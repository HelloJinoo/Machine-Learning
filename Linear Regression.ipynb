{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [1,2,3] \n",
    "y_train = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder 사용하기\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_normal = 랜덤으로 값을 하나 지정 , 배열의 크기만큼, 추가 옵션으로 stddev를 넣어 표준편차를 지정가능\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설설정\n",
    "hypothesis = W * x_train + b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설설정 , placeholder를 이용한것\n",
    "hypothesis = W * X + b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "# cost > 전체 <가설 - y>을 제곱하여 더한 후 m으로 나눈 평균. -> 계산 된 값이 아닌 그래프형태(2차방정식)가 됨. tensorflow는 실행을 위해서는\n",
    "# session이라는 객체를 사용하여 실행시켜야함!!\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#경사하강법. step = 0.01로 지정\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#경사하강법을 이용하여 cost를 작게하는 train을 구함\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session객체 생성\n",
    "sess = tf.Session()\n",
    "\n",
    "#tf.Variable을 사용하기위해서는 써줘야함....\n",
    "sess.run(tf.global_variables_initializer()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1644696 [0.23706731] [0.6447153]\n",
      "20 0.09758244 [0.6174131] [0.76595813]\n",
      "40 0.07992184 [0.66819537] [0.7443906]\n",
      "60 0.07250736 [0.68691236] [0.71078104]\n",
      "80 0.06585165 [0.7019238] [0.67750776]\n",
      "100 0.059807505 [0.71596056] [0.6456798]\n",
      "120 0.054318145 [0.72931206] [0.6153365]\n",
      "140 0.049332585 [0.7420336] [0.5864181]\n",
      "160 0.04480468 [0.75415707] [0.55885863]\n",
      "180 0.04069231 [0.7657109] [0.5325944]\n"
     ]
    }
   ],
   "source": [
    "for step in range(200) :\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0 :\n",
    "        print(step  , sess.run(cost) , sess.run(W) , sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 38.000904 [-1.7351002] [0.45943427]\n",
      "20 0.59606045 [0.21391566] [1.2386731]\n",
      "40 0.23383622 [0.4242032] [1.2567147]\n",
      "60 0.20958573 [0.46776915] [1.2049147]\n",
      "80 0.19032376 [0.4943537] [1.1489794]\n",
      "100 0.1728549 [0.5182669] [1.0950475]\n",
      "120 0.15698959 [0.54092085] [1.0435905]\n",
      "140 0.1425804 [0.56249726] [0.9945461]\n",
      "160 0.12949379 [0.5830584] [0.94780624]\n",
      "180 0.11760833 [0.60265315] [0.90326273]\n",
      "200 0.10681375 [0.621327] [0.8608127]\n",
      "220 0.09700998 [0.6391232] [0.8203576]\n",
      "240 0.08810603 [0.6560831] [0.7818039]\n",
      "260 0.08001932 [0.672246] [0.74506205]\n",
      "280 0.07267481 [0.68764913] [0.7100469]\n",
      "300 0.06600445 [0.7023285] [0.6766772]\n",
      "320 0.05994624 [0.7163181] [0.64487594]\n",
      "340 0.054444175 [0.7296501] [0.61456907]\n",
      "360 0.04944707 [0.74235547] [0.5856866]\n",
      "380 0.044908572 [0.7544639] [0.5581614]\n",
      "400 0.040786702 [0.76600325] [0.53192985]\n",
      "420 0.037043147 [0.7770002] [0.50693107]\n",
      "440 0.033643167 [0.78748035] [0.48310715]\n",
      "460 0.030555265 [0.79746795] [0.4604029]\n",
      "480 0.027750773 [0.8069863] [0.43876567]\n",
      "500 0.025203703 [0.8160572] [0.4181453]\n",
      "520 0.022890398 [0.8247018] [0.39849398]\n",
      "540 0.020789424 [0.8329402] [0.37976617]\n",
      "560 0.018881276 [0.8407914] [0.36191857]\n",
      "580 0.017148284 [0.84827363] [0.3449097]\n",
      "600 0.015574348 [0.8554042] [0.3287002]\n",
      "620 0.014144867 [0.8621997] [0.31325245]\n",
      "640 0.012846582 [0.8686758] [0.29853076]\n",
      "660 0.0116674835 [0.8748476] [0.2845009]\n",
      "680 0.010596602 [0.8807293] [0.27113035]\n",
      "700 0.009624002 [0.88633454] [0.25838822]\n",
      "720 0.008740672 [0.8916764] [0.24624497]\n",
      "740 0.007938414 [0.89676726] [0.23467235]\n",
      "760 0.007209789 [0.9016188] [0.2236436]\n",
      "780 0.0065480485 [0.9062423] [0.21313319]\n",
      "800 0.005947054 [0.9106485] [0.20311676]\n",
      "820 0.0054012053 [0.9148478] [0.19357102]\n",
      "840 0.0049054543 [0.91884965] [0.18447389]\n",
      "860 0.004455215 [0.9226634] [0.1758043]\n",
      "880 0.0040462916 [0.92629796] [0.16754213]\n",
      "900 0.003674914 [0.92976165] [0.15966828]\n",
      "920 0.003337621 [0.93306255] [0.15216447]\n",
      "940 0.0030312792 [0.93620837] [0.14501329]\n",
      "960 0.0027530591 [0.9392064] [0.13819821]\n",
      "980 0.0025003657 [0.94206345] [0.1317034]\n",
      "1000 0.0022708697 [0.9447863] [0.1255138]\n",
      "1020 0.0020624397 [0.9473811] [0.11961512]\n",
      "1040 0.0018731421 [0.9498541] [0.11399361]\n",
      "1060 0.00170122 [0.95221066] [0.10863633]\n",
      "1080 0.0015450729 [0.9544566] [0.10353082]\n",
      "1100 0.0014032634 [0.95659703] [0.09866526]\n",
      "1120 0.0012744636 [0.9586367] [0.09402835]\n",
      "1140 0.0011574907 [0.9605807] [0.0896094]\n",
      "1160 0.0010512508 [0.9624332] [0.08539808]\n",
      "1180 0.00095475884 [0.96419865] [0.08138469]\n",
      "1200 0.0008671304 [0.9658812] [0.07755994]\n",
      "1220 0.00078754086 [0.9674847] [0.07391492]\n",
      "1240 0.0007152602 [0.9690128] [0.07044122]\n",
      "1260 0.0006496099 [0.9704692] [0.06713068]\n",
      "1280 0.00058998633 [0.97185695] [0.06397576]\n",
      "1300 0.0005358352 [0.9731796] [0.06096913]\n",
      "1320 0.00048665307 [0.97444] [0.05810381]\n",
      "1340 0.00044198657 [0.9756413] [0.05537315]\n",
      "1360 0.00040141796 [0.9767861] [0.0527708]\n",
      "1380 0.00036457425 [0.977877] [0.05029077]\n",
      "1400 0.00033111023 [0.9789167] [0.04792728]\n",
      "1420 0.00030072124 [0.9799074] [0.04567494]\n",
      "1440 0.00027312103 [0.9808518] [0.04352839]\n",
      "1460 0.00024805364 [0.98175174] [0.0414827]\n",
      "1480 0.00022528449 [0.9826093] [0.03953316]\n",
      "1500 0.00020460812 [0.9834266] [0.03767527]\n",
      "1520 0.00018582905 [0.9842055] [0.03590468]\n",
      "1540 0.00016877158 [0.98494774] [0.03421731]\n",
      "1560 0.0001532813 [0.9856551] [0.03260923]\n",
      "1580 0.000139214 [0.9863293] [0.03107671]\n",
      "1600 0.00012643595 [0.9869718] [0.02961622]\n",
      "1620 0.00011483123 [0.987584] [0.02822438]\n",
      "1640 0.000104291976 [0.9881675] [0.02689796]\n",
      "1660 9.47194e-05 [0.9887236] [0.02563387]\n",
      "1680 8.602613e-05 [0.9892536] [0.02442917]\n",
      "1700 7.8130135e-05 [0.98975843] [0.02328117]\n",
      "1720 7.095904e-05 [0.99023986] [0.02218713]\n",
      "1740 6.444598e-05 [0.9906986] [0.02114438]\n",
      "1760 5.853073e-05 [0.9911357] [0.02015066]\n",
      "1780 5.315822e-05 [0.9915523] [0.01920364]\n",
      "1800 4.8280057e-05 [0.99194926] [0.01830114]\n",
      "1820 4.384856e-05 [0.99232763] [0.01744106]\n",
      "1840 3.9824157e-05 [0.99268824] [0.01662139]\n",
      "1860 3.616806e-05 [0.9930319] [0.0158402]\n",
      "1880 3.2848337e-05 [0.9933593] [0.01509574]\n",
      "1900 2.9833891e-05 [0.9936714] [0.0143863]\n",
      "1920 2.7095572e-05 [0.99396884] [0.01371022]\n",
      "1940 2.4608555e-05 [0.9942523] [0.01306587]\n",
      "1960 2.2349579e-05 [0.99452245] [0.01245181]\n",
      "1980 2.0298057e-05 [0.9947799] [0.0118666]\n",
      "2000 1.8435114e-05 [0.9950252] [0.01130889]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    # sess.run( [리스트안에 실행시킬 그래프를 여러개 넣을수 잇음] , feed_dict 사용될 데이터들 )\n",
    "    \n",
    "    cost_val, W_val, b_val , _ = sess.run([cost, W, b, train],feed_dict={X: [1, 2, 3], Y: [1, 2, 3]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0063341]\n",
      "[ 7.9715104  8.966536   9.961561  21.901863 ]\n",
      "[10.956586]\n"
     ]
    }
   ],
   "source": [
    "#학습된 model을 이용하여 test해보기\n",
    "print(sess.run(hypothesis , feed_dict={X:[1]}))\n",
    "print(sess.run(hypothesis , feed_dict={X:[8,9,10,22]}))\n",
    "print(sess.run(hypothesis , feed_dict={X:[11]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
